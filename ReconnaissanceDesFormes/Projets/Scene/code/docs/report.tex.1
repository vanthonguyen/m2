\documentclass[french,12pt,a4paper,oneside,notitlepage]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=2.5cm]{geometry}
\usepackage[french]{babel}
\usepackage{xcolor}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsthm}
%\usepackage{fourier}
\usepackage{hyperref}   % links im text
\usepackage{enumerate}  % for advanced numbering of lists
\usepackage{fancyhdr}  
\usepackage{caption}
\usepackage{listings}
%\usepackage{mathtools}
\usepackage{amsmath}   %arraycolsep
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{color}
\usepackage{pdflscape}
\makeatletter
\definecolor{bl}{rgb}{0,0.2,0.6}
\let\LaTeX@startsection\@startsection
\renewcommand{\@startsection}[6]{\LaTeX@startsection%
{#1}{#2}{#3}{#4}{#5}{\color{bl}\raggedright #6}}
\renewcommand{\thesection}{\@arabic\c@section}{\color{bl}}
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
  {-3.25ex\@plus -1ex \@minus -.2ex}%
  {1.5ex \@plus .2ex}%
  {\normalfont\normalsize\bfseries}}
\makeatother

\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{%
  \parbox{\textwidth}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}
\lstset{frame=lrb,xleftmargin=\fboxsep,xrightmargin=-\fboxsep}

\lstset{
 	language=C++,
% 	captionpos=b,
 	tabsize=3,
 	frame=single,
 	xleftmargin=\fboxsep,
 	xrightmargin=-\fboxsep,
 	keywordstyle=\color{blue},
 	commentstyle=\color{gray},
 	stringstyle=\color{green},
	extendedchars=true,
% 	numbers=left,
 	numberstyle=\tiny,
 	numbersep=5pt,
 	breaklines=true,
 	showstringspaces=false,
 	basicstyle=\footnotesize\ttfamily,
 	emph={label},
 	inputencoding=utf8,
 	extendedchars=true, 	
 	  literate=%
 	  {é}{{\'{e}}}1
 	  {è}{{\`{e}}}1
 	  {ê}{{\^{e}}}1
 	  {ë}{{\¨{e}}}1
 	  {û}{{\^{u}}}1
 	  {ù}{{\`{u}}}1
 	  {â}{{\^{a}}}1
 	  {à}{{\`{a}}}1
 	  {î}{{\^{i}}}1
 	  {ç}{{\c{c}}}1
 	  {Ç}{{\c{C}}}1
 	  {É}{{\'{E}}}1
 	  {Ê}{{\^{E}}}1
 	  {À}{{\`{A}}}1
 	  {Â}{{\^{A}}}1
 	  {Î}{{\^{I}}}1	
}



%Page
% type user-defined commands here
\begin{document}
\title{RAPPORT DU PROJET 3\\
  Études et expérimentation de la classification des scènes naturelles}   % 
  \author{Rédigé par:\\
      Nguyen Van Tho \& Nguyen Quoc Khai\vspace{1cm}\\
  Sous la supervision de :\\
  Mr HO Tuong Vinh}         

%\date{ Décembre, 2013}    % type date between braces

\maketitle

\section{Introduction}
% Demarche qui est fait
% - comment obtenir des descripteurs?
% - la methode pour reconnaitre le document
%  
% Le résultat, expérimentation, expliquer pourquoi avoir ces résultats?
% Perspective: qu'est-ce qui peut fait pour améliorer le travail?
La reconnaissance et la catégorie des images sont importantes pour accéder à l'information visuelle au niveau d'objets et de types de
scènes. Pour l'instant, un des types de reconnaissances le plus difficile est la reconnaissance des scènes naturelles.
En fait, ce type de reconnaissance est défié par les défis tel ques la variation de point de vue (figure 1), la
différence d'échelle (figure 2), le changement d'illumination (figure 3), le désordre du fond (figure 4), l'occlusion
(figure 5) et la déformation (figure 6). 

La reconnaissance des scènes naturelles ont beaucoup d'application dans plusieurs domaines. Nous pouvons lister quelques applications principales de la reconnaissance des scènes: 
\
\section{État de l'art}
Plusieurs techniques ont été proposées au cours de ces dernières années afin de faciliter la classification des scènes naturelles. Les méthodes au dessous permet décrire les idées principales des méthodes étudiées au cours la durée de ce TP.

\pagebreak
\subsection{Approche par mots visuels « Visual Word »}
\subsubsection{Caractéristiques : }
On peut voir l'idée de cette méthode par l'image ci-dessous :
\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=8cm]{img1.png}
	\end{center}
	 \caption{Idée de la méthode « mots visuels »}
\end{figure}\\

Cette méthode obtient des caractéristiques locales de l'image : région « stables », points d'intérêt (SIFT, SURF...), etc. Ensuite, elle trouve des caractéristiques qui se répètent dans les images (construction d'un vocabulaire). Dans cette méthode, une image est décrite par les mots visuels qu'elle contient. Ces mots ne sont pas dans l'ordre. Dans cette méthode, on considère une image comme un sac de mots visuels.

\subsubsection{Algorithme}
On peut décrire la méthode mots visuels en 3 étapes :
\begin{enumerate}
\item Trouver les caractéristiques stables des images
\item Construire un dictionnaire par calculer les histogrammes
\item Décrire chaque image comme un sac de mots visuels
\end{enumerate}

\subsubsection{Reconnaissance par mots visuels}
Après avoir détecté des caractéristiques et construit d'un dictionnaire, cette méthode peut reconnaitre ou classifier des objets en comparant le sac de mots de chaque image de test avec les sacs de mots des images d'apprentissage.\\

\pagebreak
La méthode mots visuels peut être résumé par cette image :
\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=8cm]{img2.png}
	\end{center}
	 \caption{Résumé de la méthode « mots visuels »}
\end{figure}\\

\subsection{Méthode Beyond Bags of Features : Spatial Pyramid Matching}
Basée sur la même idée avec la méthode bag of visual word, cette méthode prend aussi des points intérêts et construit les vocabulaires. Autrement dit, la méthode <<Spatial Pyramid Matching>> est différente dans l'étape de faire la correspondance.

\subsubsection{Pyramid Match Kernels}
Cette méthode divise l'image en des bloques pour faire la correspondance et en des niveaux différents. Dans les niveaux différents, le nombre de bloques divisés est différent. Le nombre de bloques est augmenté quand le niveau augmente. $l$ signifie le niveau. $l = 0, 1, 2, ...$.
Une fois que l'on a calculé les histogrammes, le nombre de correspondance est calculé par l'histogramme d'intersection :
\begin{equation}
I(H^l_X,H^l_Y) = \sum_{i=1}^{D} min(H^l_X(i),H^l_Y(i))
\end{equation}
\textit{X, Y sont deux ensembles de points que l'on veut faire la correspondance.}\\
\textit{$H^l_X, H^l_Y$ sont les histogrammes (nombre de points) de X et de Y au niveau $l$.}\\
\textit{$D$ est le nombre de bloques et $H^l_X(i)$ est l'histogramme de $X$ au niveau $l$ dans le bloque $i$}\\
\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=8cm]{img3.png}
	\end{center}
	 \caption{Exemple de trois niveaux de la méthode Pyramid Matching}
\end{figure}\\



\pagebreak
\section{Méthodes proposées}
En cherchant une méthode qui rend un résultat acceptable et qui est faisable dans le 
carde un projet universitaire, nous avons choisi parmi les méthodes présentées dans la 
partie l'état de l'art la méthode "bag of visual word". En effet, cette méthode est une 
combinaison de plusieurs méthodes. La méthode a des étapes suivantes: 
\begin{itemize}
 \item Détection des points d'intérêt et ses descripteurs
 \item Regroupement (Cluster) ces descripteurs pour définir un dictionnaire des mots, 
chaque centroïde est un mot 
 \item Calcul les histogrammes de mots des images d'apprentissage selon le dictionnaire
 \item Classification les images de test en utilisant les histogrammes de mots
\end{itemize}

À chaque étape, on peut utiliser des méthodes différente. Nous choisissons la méthode 
SIFT afin d'extraire les points d'intérêt et ses descripteurs. En suite, la méthode 
Kmeans [1] est utilisée pour le regroupement des descripteurs afin de définir un 
dictionnaire.
Pour la tâche de classification nous choisissons la méthode support vector machine (SVM) 
[2] qui rend un bon résultat et qui est vérifié dans l'était de l'art. Nous avons 
expérimenté 2 noyaux: linaire et RBF (Gaussien), le résultat de notre expérimentation 
montre que le noyau gaussien est plus approprié au ce genre de problème. Donc, nous 
ne présentons que le résultat avec le noyau gaussien.

\section{Expérimentation}
Nous avons fait plusieurs expérimentation afin d'évaluer notre approche et d'examiner l'impact du nombre de scène et de
nombre des images sur le résultat. D'abord, nous fixons le nombre de mot du vocabulaire 
de 1000 et trouver les valeur optimale des autres paramètres de SVM. En suite, en 
utilisant ces valeurs optimales, nous expérimentons plusieurs valeur de taille du 
vocabulaire.
\subsection{Scénarios}
\subsubsection{Expérimentation avec une partie des données}
Vu que le temps de calcul de programme est élevé, nous l'expérimentons pour but de 
trouver les valeurs optimales de c et gamma de SVM. De plus, nous souhaitons examiner 
l'impact de nombre de scène en constatant que le taux de reconnaissance diminue quand le 
nombre de scène augmente. Le tableau ci-dessous présente les paramètres que nous 
utilisons pour cette expérimentation. D'abord, nous expérimentons avec la valeur fixée de 
C (300) alors que la valeur de gamma est variée de 0.05 à 2.0. La valeur optimale de 
gamma est ensuite utilisée pour trouver la valeur optimale de C.

\begin{table}[!ht]
  \begin{center}
	\begin{tabular}{|l|l|l|l|}
	  \hline
	  C& gamma & Nombre de scène & Nombre d'image / scène\\
	  \hline
	  300 & 0.05 0.1 0.5 1.0 2.0 & 13 & 120\\
	  \hline
	  10 100 200 300 400 500 & gamma optimale & 13 & 120\\
	  \hline
	\end{tabular}
  \end{center}
\end{table}

\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=12cm]{findgamma.png}
	\end{center}
	 \caption{Taux de reconnaissance avec une valeur fixée de C = 300 et des variation de 
gamma}
\end{figure}

Au vu des les taux de reconnaissance dans la figure ci-dessus, nous pouvons choisir la 
valeur optimale pour gamma. Avec la une valeur de gamma de 0.5, nous obtenons le taux 
maximum de reconnaissance. Nous allons utiliser cette valeur pour l'étape suivante: 
trouver la valeur optimale de C.

\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=12cm]{findc.png}
	\end{center}
	 \caption{Taux de reconnaissance avec une valeur fixée de gamma = 0.5 et des 
variation de C}
\end{figure}

En voyant la figure ci-dessus nous constatons que la valeur optimale de C est 300. Nous 
allons utiliser cette valeur de C et la valeur de gamma = 0.5 pour les autres 
expérimentations.
\subsubsection{Expérimentation avec un nombre de scène plus petit}
Dans cette expérimentation, nous limitons le nombre de scène à 4 afin d'examiner l'impact 
de nombre de scène sur le résultat. En fait, quand le nombre de scène augmente, le taux 
de reconnaissance diminue. 
\begin{table}[!ht]
  \begin{center}
	\begin{tabular}{|l|l|l|l|}
	  \hline
	  C& gamma & Nombre de scène & Nombre d'image / scène\\
	  \hline
	  300 & 0.5 & 4 & maximum\\
	  \hline
	\end{tabular}
  \end{center}
\end{table}
\subsubsection{Expérimentation avec les valeurs différentes de la taille de vocabulaire }
La taille de vocabulaire influence beaucoup le taux de reconnaissance [3]. Nous voulons 
donc expérimenter plusieurs valeurs de la taille de vocabulaire afin de trouver la 
meilleure valeur. De plus, nous expérimentons le programme avec toutes les données et 
avec les paramètres optimales.
\begin{table}[!ht]
  \begin{center}
	\begin{tabular}{|l|l|l|l|l|}
	  \hline
	  Taille de vocabulaire& gamma & Nombre de scène & Nombre d'image / scène\\
	  \hline
	  500, 1000, 2000, 5000 & 300 & 0.5 & 13 & maximum\\
	  \hline
	\end{tabular}
  \end{center}
\end{table}

\begin{figure}[ht]
	\begin{center}
%	  \includegraphics[width=12cm]{dic.png}
	\end{center}
	 \caption{Taux de reconnaissance avec des tailles différentes du vocabulaire}
\end{figure}
À partir du résultat de cette expérimentation nous pouvons conclure que la taille du 
vocabulaire influence beaucoup le taux de reconnaissance. En fait, dans notre cas, la 
taille de vocabulaire optimale est .
Cependant, le temps 
d'apprentissage est augmente quand cette taille augmente.  
\subsection{Critères d'évaluation}
 Dans le but d’avoir une vue plus précise des performances de notre programme, nous utilisons  
  les indicateurs suivants :
  \begin{itemize}
   \item Matrice de confusion, le taux de rappel et le taux de précision de chaque scène. 
Cela est pour une analyse plus détaille
  \item Taux de reconnaissance (taux) qui est le rapport du nombre de bonnes 
reconnaissances par 
  le nombre total. 
  \item Temps d'apprentissage du programme
  \item Temps de reconnaissance
  \end{itemize}

\subsection{Méthode d'évaluation}
Nous appliquons la méthode d'évaluation k-fold cross validation afin d'assurer que notre 
programme va bien prédire les nouvelles données. Puisque les données proposées sont assez 
petites: 6 images pour le type 1, 6 images pour le type 2, \dots nous choisissons 3 pour la 
valeur de k. Autrement, nous divisons les données en trois ensembles et chaque 
expérimentation nous prenons un ensemble  la validation et deux autres ensembles pour 
l'apprentissage. La figure ci-dessous l'explique.

\begin{figure}[ht]
	\begin{center}
	  \includegraphics[width=8cm]{3fold.jpg}
	\end{center}
	 \caption{Méthode 3-fold cross validation utilisée}
\end{figure}

\subsubsection{Résultat}

\subsection{Analyses}
\section{Conclusion et perspective}
\section*{Références}
[1]Hartigan, John A., and Manchek A. Wong. "Algorithm AS 136: A k-means clustering 
algorithm." Journal of the Royal Statistical Society. Series C (Applied Statistics) 28.1 
(1979): 100-108.
[2]Burges, Christopher JC. "A tutorial on support vector machines for pattern 
recognition." Data mining and knowledge discovery 2.2 (1998): 121-167.
APA	
[3] Yang, Jun, et al. "Evaluating bag-of-visual-words representations in scene 
classification." Proceedings of the international workshop on Workshop on multimedia 
information retrieval. ACM, 2007.
\end{document}
